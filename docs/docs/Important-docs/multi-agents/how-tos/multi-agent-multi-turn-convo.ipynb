{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2b182eb-1e31-43c8-85b1-706508dfa370",
   "metadata": {},
   "source": [
    "# How to add multi-turn conversation in a multi-agent application\n",
    "\n",
    "!!! info \"Prerequisites\"\n",
    "    This guide assumes familiarity with the following:\n",
    "\n",
    "    - [How to implement handoffs between agents](../agent-handoffs)\n",
    "    - [Multi-agent systems](../../concepts/multi_agent)\n",
    "    - [Human-in-the-loop](../../concepts/human_in_the_loop)\n",
    "    - [Command](../../concepts/low_level/#command)\n",
    "    - [LangGraph Glossary](../../concepts/low_level/)\n",
    "\n",
    "\n",
    "In this how-to guide, we’ll build an application that allows an end-user to engage in a *multi-turn conversation* with one or more agents. We'll create a node that uses an [`interrupt`](../../reference/types/#langgraph.types.interrupt) to collect user input and routes back to the **active** agent.\n",
    "\n",
    "The agents will be implemented as nodes in a graph that executes agent steps and determines the next action:  \n",
    "\n",
    "1. **Wait for user input** to continue the conversation, or  \n",
    "2. **Route to another agent** (or back to itself, such as in a loop) via a [**handoff**](../../concepts/multi_agent/#handoffs).\n",
    "\n",
    "```python\n",
    "def human(state: MessagesState) -> Command[Literal[\"agent\", \"another_agent\"]]:\n",
    "    \"\"\"A node for collecting user input.\"\"\"\n",
    "    user_input = interrupt(value=\"Ready for user input.\")\n",
    "\n",
    "    # Determine the active agent.\n",
    "    active_agent = ...\n",
    "\n",
    "    ...\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [{\n",
    "                \"role\": \"human\",\n",
    "                \"content\": user_input,\n",
    "            }]\n",
    "        },\n",
    "        goto=active_agent\n",
    "    )\n",
    "\n",
    "def agent(state) -> Command[Literal[\"agent\", \"another_agent\", \"human\"]]:\n",
    "    # The condition for routing/halting can be anything, e.g. LLM tool call / structured output, etc.\n",
    "    goto = get_next_agent(...)  # 'agent' / 'another_agent'\n",
    "    if goto:\n",
    "        return Command(goto=goto, update={\"my_state_key\": \"my_state_value\"})\n",
    "    else:\n",
    "        return Command(goto=\"human\") # Go to human node\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa4444-cd06-4813-b9ca-c9700fe12cb7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05038da0-31df-4066-a1a4-c4ccb5db4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcff5d4-130e-426d-9285-40d0f72c7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec6e48-85dc-4905-ba50-985e5d4788e6",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c217c3fe-ca50-45a1-be91-912bc83ed8b3",
   "metadata": {},
   "source": [
    "## Define agents\n",
    "\n",
    "In this example, we will build a team of travel assistant agents that can communicate with each other via handoffs.\n",
    "\n",
    "We will create 2 agents:\n",
    "\n",
    "* `travel_advisor`: can help with travel destination recommendations. Can ask `hotel_advisor` for help.\n",
    "* `hotel_advisor`: can help with hotel recommendations. Can ask `travel_advisor` for help.\n",
    "\n",
    "We will be using prebuilt [`create_react_agent`][langgraph.prebuilt.chat_agent_executor.create_react_agent] for the agents - each agent will have tools specific to its area of expertise as well as a special [tool for handoffs](../agent-handoffs#implementing-handoffs-using-tools) to another agent.\n",
    "\n",
    "First, let's define the tools we'll be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51463a-4425-44ad-91d5-f21fd5b4e3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.tools.base import InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_travel_recommendations():\n",
    "    \"\"\"Get recommendation for travel destinations\"\"\"\n",
    "    return random.choice([\"aruba\", \"turks and caicos\"])\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_hotel_recommendations(location: Literal[\"aruba\", \"turks and caicos\"]):\n",
    "    \"\"\"Get hotel recommendations for a given destination.\"\"\"\n",
    "    return {\n",
    "        \"aruba\": [\n",
    "            \"The Ritz-Carlton, Aruba (Palm Beach)\"\n",
    "            \"Bucuti & Tara Beach Resort (Eagle Beach)\"\n",
    "        ],\n",
    "        \"turks and caicos\": [\"Grace Bay Club\", \"COMO Parrot Cay\"],\n",
    "    }[location]\n",
    "\n",
    "\n",
    "def make_handoff_tool(*, agent_name: str):\n",
    "    \"\"\"Create a tool that can return handoff via a Command\"\"\"\n",
    "    tool_name = f\"transfer_to_{agent_name}\"\n",
    "\n",
    "    @tool(tool_name)\n",
    "    def handoff_to_agent(\n",
    "        state: Annotated[dict, InjectedState],\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ):\n",
    "        \"\"\"Ask another agent for help.\"\"\"\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"Successfully transferred to {agent_name}\",\n",
    "            \"name\": tool_name,\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(\n",
    "            # navigate to another agent node in the PARENT graph\n",
    "            goto=agent_name,\n",
    "            graph=Command.PARENT,\n",
    "            # This is the state update that the agent `agent_name` will see when it is invoked.\n",
    "            # We're passing agent's FULL internal message history AND adding a tool message to make sure\n",
    "            # the resulting chat history is valid.\n",
    "            update={\"messages\": state[\"messages\"] + [tool_message]},\n",
    "        )\n",
    "\n",
    "    return handoff_to_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d661e-6ba4-42b9-bc7f-6c8c423e3419",
   "metadata": {},
   "source": [
    "Let's now create our agents using the the prebuilt [`create_react_agent`][langgraph.prebuilt.chat_agent_executor.create_react_agent]. We'll also define a dedicated `human` node with an [`interrupt`][langgraph.types.interrupt] -- we will route to this node after the final response from the agents. Note that to do so we're wrapping each agent invocation in a separate node function that returns `Command(goto=\"human\", ...)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4bdbff-9461-46cc-aee9-8a22d3c3d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import MessagesState, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent, InjectedState\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
    "\n",
    "# Define travel advisor tools and ReAct agent\n",
    "travel_advisor_tools = [\n",
    "    get_travel_recommendations,\n",
    "    make_handoff_tool(agent_name=\"hotel_advisor\"),\n",
    "]\n",
    "travel_advisor = create_react_agent(\n",
    "    model,\n",
    "    travel_advisor_tools,\n",
    "    prompt=(\n",
    "        \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc). \"\n",
    "        \"If you need hotel recommendations, ask 'hotel_advisor' for help. \"\n",
    "        \"You MUST include human-readable response before transferring to another agent.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def call_travel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"hotel_advisor\", \"human\"]]:\n",
    "    # You can also add additional logic like changing the input to the agent / output from the agent, etc.\n",
    "    # NOTE: we're invoking the ReAct agent with the full history of messages in the state\n",
    "    response = travel_advisor.invoke(state)\n",
    "    return Command(update=response, goto=\"human\")\n",
    "\n",
    "\n",
    "# Define hotel advisor tools and ReAct agent\n",
    "hotel_advisor_tools = [\n",
    "    get_hotel_recommendations,\n",
    "    make_handoff_tool(agent_name=\"travel_advisor\"),\n",
    "]\n",
    "hotel_advisor = create_react_agent(\n",
    "    model,\n",
    "    hotel_advisor_tools,\n",
    "    prompt=(\n",
    "        \"You are a hotel expert that can provide hotel recommendations for a given destination. \"\n",
    "        \"If you need help picking travel destinations, ask 'travel_advisor' for help.\"\n",
    "        \"You MUST include human-readable response before transferring to another agent.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def call_hotel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"travel_advisor\", \"human\"]]:\n",
    "    response = hotel_advisor.invoke(state)\n",
    "    return Command(update=response, goto=\"human\")\n",
    "\n",
    "\n",
    "def human_node(\n",
    "    state: MessagesState, config\n",
    ") -> Command[Literal[\"hotel_advisor\", \"travel_advisor\", \"human\"]]:\n",
    "    \"\"\"A node for collecting user input.\"\"\"\n",
    "\n",
    "    user_input = interrupt(value=\"Ready for user input.\")\n",
    "\n",
    "    # identify the last active agent\n",
    "    # (the last active node before returning to human)\n",
    "    langgraph_triggers = config[\"metadata\"][\"langgraph_triggers\"]\n",
    "    if len(langgraph_triggers) != 1:\n",
    "        raise AssertionError(\"Expected exactly 1 trigger in human node\")\n",
    "\n",
    "    active_agent = langgraph_triggers[0].split(\":\")[1]\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"human\",\n",
    "                    \"content\": user_input,\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        goto=active_agent,\n",
    "    )\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"travel_advisor\", call_travel_advisor)\n",
    "builder.add_node(\"hotel_advisor\", call_hotel_advisor)\n",
    "\n",
    "# This adds a node to collect human input, which will route\n",
    "# back to the active agent.\n",
    "builder.add_node(\"human\", human_node)\n",
    "\n",
    "# We'll always start with a general travel advisor.\n",
    "builder.add_edge(START, \"travel_advisor\")\n",
    "\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77921f6-599d-443f-8b15-56b1adafd3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af856e1b-41fc-4041-8cbf-3818a60088e0",
   "metadata": {},
   "source": [
    "## Test multi-turn conversation\n",
    "\n",
    "Let's test a multi turn conversation with this application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e0cf1-d13a-4026-8f89-bdab67d1ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "thread_config = {\"configurable\": {\"thread_id\": uuid.uuid4()}}\n",
    "\n",
    "inputs = [\n",
    "    # 1st round of conversation,\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"i wanna go somewhere warm in the caribbean\"}\n",
    "        ]\n",
    "    },\n",
    "    # Since we're using `interrupt`, we'll need to resume using the Command primitive.\n",
    "    # 2nd round of conversation,\n",
    "    Command(\n",
    "        resume=\"could you recommend a nice hotel in one of the areas and tell me which area it is.\"\n",
    "    ),\n",
    "    # 3rd round of conversation,\n",
    "    Command(\n",
    "        resume=\"i like the first one. could you recommend something to do near the hotel?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "for idx, user_input in enumerate(inputs):\n",
    "    print()\n",
    "    print(f\"--- Conversation Turn {idx + 1} ---\")\n",
    "    print()\n",
    "    print(f\"User: {user_input}\")\n",
    "    print()\n",
    "    for update in graph.stream(\n",
    "        user_input,\n",
    "        config=thread_config,\n",
    "        stream_mode=\"updates\",\n",
    "    ):\n",
    "        for node_id, value in update.items():\n",
    "            if isinstance(value, dict) and value.get(\"messages\", []):\n",
    "                last_message = value[\"messages\"][-1]\n",
    "                if isinstance(last_message, dict) or last_message.type != \"ai\":\n",
    "                    continue\n",
    "                print(f\"{node_id}: {last_message.content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
