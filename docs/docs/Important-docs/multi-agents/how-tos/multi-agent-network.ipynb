{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87684b48-150e-4e15-b0a5-a9dd7851f8fb",
   "metadata": {},
   "source": [
    "# How to build a multi-agent network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c65639c-9705-49f1-840a-370718852e98",
   "metadata": {},
   "source": [
    "!!! info \"Prerequisites\" \n",
    "    This guide assumes familiarity with the following:\n",
    "\n",
    "    - [How to implement handoffs between agents](../agent-handoffs)\n",
    "    - [Multi-agent systems](../../concepts/multi_agent)\n",
    "    - [Command](../../concepts/low_level/#command)\n",
    "    - [LangGraph Glossary](../../concepts/low_level/)\n",
    "\n",
    "In this how-to guide we will demonstrate how to implement a [multi-agent network](../../concepts/multi_agent#network) architecture where each agent can communicate with every other agent (many-to-many connections) and can decide which agent to call next. Individual agents will be defined as graph nodes.\n",
    "\n",
    "To implement communication between the agents, we will be using [handoffs](../agent-handoffs):\n",
    "\n",
    "```python\n",
    "def agent(state) -> Command[Literal[\"agent\", \"another_agent\"]]:\n",
    "    # the condition for routing/halting can be anything, e.g. LLM tool call / structured output, etc.\n",
    "    goto = get_next_agent(...)  # 'agent' / 'another_agent'\n",
    "    return Command(\n",
    "        # Specify which agent to call next\n",
    "        goto=goto,\n",
    "        # Update the graph state\n",
    "        update={\"my_state_key\": \"my_state_value\"}\n",
    "    )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa4444-cd06-4813-b9ca-c9700fe12cb7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's install the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05038da0-31df-4066-a1a4-c4ccb5db4d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcff5d4-130e-426d-9285-40d0f72c7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ec6e48-85dc-4905-ba50-985e5d4788e6",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">Set up <a href=\"https://smith.langchain.com\">LangSmith</a> for LangGraph development</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph â€” read more about how to get started <a href=\"https://docs.smith.langchain.com\">here</a>. \n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a53f304-3709-4df7-8714-1ca61e615743",
   "metadata": {},
   "source": [
    "## Using a custom agent implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cd131b-f0c2-4b69-887f-2cbd5afb14a7",
   "metadata": {},
   "source": [
    "In this example we will build a team of travel assistant agents that can communicate with each other via handoffs.\n",
    "\n",
    "We will create 2 agents:\n",
    "\n",
    "* `travel_advisor`: can help with travel destination recommendations. Can ask `hotel_advisor` for help.\n",
    "* `hotel_advisor`: can help with hotel recommendations. Can ask `travel_advisor` for help.\n",
    "\n",
    "This is a fully-connected network - every agent can talk to any other agent. \n",
    "\n",
    "Each agent will have a corresponding node function that can conditionally return a `Command` object (the handoff). The node function will use an LLM with a system prompt and a tool that lets it signal when it needs to hand off to another agent. If the LLM responds with the tool calls, we will return a `Command(goto=<other_agent>)`.\n",
    "\n",
    "> **Note**: while we're using tools for the LLM to signal that it needs a handoff, the condition for the handoff can be anything: a specific response text from the LLM, structured output from the LLM, any other custom logic, etc.\n",
    "\n",
    "Now, let's define our agent nodes and graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3f270f-4894-4a2d-98cd-e855353e3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import MessagesState, StateGraph, START\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
    "\n",
    "\n",
    "# Define a helper for each of the agent nodes to call\n",
    "\n",
    "\n",
    "@tool\n",
    "def transfer_to_travel_advisor():\n",
    "    \"\"\"Ask travel advisor for help.\"\"\"\n",
    "    # This tool is not returning anything: we're just using it\n",
    "    # as a way for LLM to signal that it needs to hand off to another agent\n",
    "    # (See the paragraph above)\n",
    "    return\n",
    "\n",
    "\n",
    "@tool\n",
    "def transfer_to_hotel_advisor():\n",
    "    \"\"\"Ask hotel advisor for help.\"\"\"\n",
    "    return\n",
    "\n",
    "\n",
    "def travel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"hotel_advisor\", \"__end__\"]]:\n",
    "    system_prompt = (\n",
    "        \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc). \"\n",
    "        \"If you need hotel recommendations, ask 'hotel_advisor' for help.\"\n",
    "    )\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    ai_msg = model.bind_tools([transfer_to_hotel_advisor]).invoke(messages)\n",
    "    # If there are tool calls, the LLM needs to hand off to another agent\n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        # NOTE: it's important to insert a tool message here because LLM providers are expecting\n",
    "        # all AI messages to be followed by a corresponding tool result message\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(goto=\"hotel_advisor\", update={\"messages\": [ai_msg, tool_msg]})\n",
    "\n",
    "    # If the expert has an answer, return it directly to the user\n",
    "    return {\"messages\": [ai_msg]}\n",
    "\n",
    "\n",
    "def hotel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"travel_advisor\", \"__end__\"]]:\n",
    "    system_prompt = (\n",
    "        \"You are a hotel expert that can provide hotel recommendations for a given destination. \"\n",
    "        \"If you need help picking travel destinations, ask 'travel_advisor' for help.\"\n",
    "    )\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "    ai_msg = model.bind_tools([transfer_to_travel_advisor]).invoke(messages)\n",
    "    # If there are tool calls, the LLM needs to hand off to another agent\n",
    "    if len(ai_msg.tool_calls) > 0:\n",
    "        tool_call_id = ai_msg.tool_calls[-1][\"id\"]\n",
    "        # NOTE: it's important to insert a tool message here because LLM providers are expecting\n",
    "        # all AI messages to be followed by a corresponding tool result message\n",
    "        tool_msg = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": \"Successfully transferred\",\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(goto=\"travel_advisor\", update={\"messages\": [ai_msg, tool_msg]})\n",
    "\n",
    "    # If the expert has an answer, return it directly to the user\n",
    "    return {\"messages\": [ai_msg]}\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"travel_advisor\", travel_advisor)\n",
    "builder.add_node(\"hotel_advisor\", hotel_advisor)\n",
    "# we'll always start with a general travel advisor\n",
    "builder.add_edge(START, \"travel_advisor\")\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af856e1b-41fc-4041-8cbf-3818a60088e0",
   "metadata": {},
   "source": [
    "First, let's invoke it with a generic input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058f3d96-534f-4b97-afb3-799ba81224ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "\n",
    "def pretty_print_messages(update):\n",
    "    if isinstance(update, tuple):\n",
    "        ns, update = update\n",
    "        # skip parent graph updates in the printouts\n",
    "        if len(ns) == 0:\n",
    "            return\n",
    "\n",
    "        graph_id = ns[-1].split(\":\")[0]\n",
    "        print(f\"Update from subgraph {graph_id}:\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    for node_name, node_update in update.items():\n",
    "        print(f\"Update from node {node_name}:\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "        for m in convert_to_messages(node_update[\"messages\"]):\n",
    "            m.pretty_print()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a0d4df-ff99-40f0-92a8-0b3f2c591040",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"i wanna go somewhere warm in the caribbean\")]}\n",
    "):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ea9aa-36ee-40a1-a5fc-b44a079786a9",
   "metadata": {},
   "source": [
    "You can see that in this case only the first agent (`travel_advisor`) ran. Let's now ask for more recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a547d4-0a15-43bd-aeed-c9ba1dfe388f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"i wanna go somewhere warm in the caribbean. pick one destination and give me hotel recommendations\",\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    pretty_print_messages(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c66f91-39b0-4ed2-91e8-6daf6d124f47",
   "metadata": {},
   "source": [
    "Voila - `travel_advisor` picks a destination and then makes a decision to call `hotel_advisor` for more info!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ff04a-f2c6-408c-a332-1346a96d7f61",
   "metadata": {},
   "source": [
    "## Using with a prebuilt ReAct agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b560c3c-fa17-4879-a40f-147fc483c41c",
   "metadata": {},
   "source": [
    "Let's now see how we can implement the same team of travel agents, but give each of the agents some tools to call. We'll be using prebuilt [`create_react_agent`][langgraph.prebuilt.chat_agent_executor.create_react_agent] to implement the agents. First, let's create some of the tools that the agents will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e31f258-ec28-4020-b86d-c91dfa9a3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing_extensions import Literal\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_travel_recommendations():\n",
    "    \"\"\"Get recommendation for travel destinations\"\"\"\n",
    "    return random.choice([\"aruba\", \"turks and caicos\"])\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_hotel_recommendations(location: Literal[\"aruba\", \"turks and caicos\"]):\n",
    "    \"\"\"Get hotel recommendations for a given destination.\"\"\"\n",
    "    return {\n",
    "        \"aruba\": [\n",
    "            \"The Ritz-Carlton, Aruba (Palm Beach)\"\n",
    "            \"Bucuti & Tara Beach Resort (Eagle Beach)\"\n",
    "        ],\n",
    "        \"turks and caicos\": [\"Grace Bay Club\", \"COMO Parrot Cay\"],\n",
    "    }[location]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64455a-8b28-42f0-90ac-a0ab92a433a3",
   "metadata": {},
   "source": [
    "Let's also write a helper to create a handoff tool. See [this how-to guide](../agent-handoffs#implementing-handoffs-using-tools) for a more in-depth walkthrough of how to make a handoff tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82280f-d171-4338-8ead-d1b3029ad9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.tools.base import InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "\n",
    "\n",
    "def make_handoff_tool(*, agent_name: str):\n",
    "    \"\"\"Create a tool that can return handoff via a Command\"\"\"\n",
    "    tool_name = f\"transfer_to_{agent_name}\"\n",
    "\n",
    "    @tool(tool_name)\n",
    "    def handoff_to_agent(\n",
    "        state: Annotated[dict, InjectedState],\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ):\n",
    "        \"\"\"Ask another agent for help.\"\"\"\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"Successfully transferred to {agent_name}\",\n",
    "            \"name\": tool_name,\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(\n",
    "            # navigate to another agent node in the PARENT graph\n",
    "            goto=agent_name,\n",
    "            graph=Command.PARENT,\n",
    "            # This is the state update that the agent `agent_name` will see when it is invoked.\n",
    "            # We're passing agent's FULL internal message history AND adding a tool message to make sure\n",
    "            # the resulting chat history is valid.\n",
    "            update={\"messages\": state[\"messages\"] + [tool_message]},\n",
    "        )\n",
    "\n",
    "    return handoff_to_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dbc3bd-27b9-4d79-b5dd-be592bc50f74",
   "metadata": {},
   "source": [
    "Now let's define our agent nodes and combine them into a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b638d6c4-3de6-4921-980c-2df1bd1cc9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "model = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
    "\n",
    "# Define travel advisor ReAct agent\n",
    "travel_advisor_tools = [\n",
    "    get_travel_recommendations,\n",
    "    make_handoff_tool(agent_name=\"hotel_advisor\"),\n",
    "]\n",
    "travel_advisor = create_react_agent(\n",
    "    model,\n",
    "    travel_advisor_tools,\n",
    "    prompt=(\n",
    "        \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc). \"\n",
    "        \"If you need hotel recommendations, ask 'hotel_advisor' for help. \"\n",
    "        \"You MUST include human-readable response before transferring to another agent.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def call_travel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"hotel_advisor\", \"__end__\"]]:\n",
    "    # You can also add additional logic like changing the input to the agent / output from the agent, etc.\n",
    "    # NOTE: we're invoking the ReAct agent with the full history of messages in the state\n",
    "    return travel_advisor.invoke(state)\n",
    "\n",
    "\n",
    "# Define hotel advisor ReAct agent\n",
    "hotel_advisor_tools = [\n",
    "    get_hotel_recommendations,\n",
    "    make_handoff_tool(agent_name=\"travel_advisor\"),\n",
    "]\n",
    "hotel_advisor = create_react_agent(\n",
    "    model,\n",
    "    hotel_advisor_tools,\n",
    "    prompt=(\n",
    "        \"You are a hotel expert that can provide hotel recommendations for a given destination. \"\n",
    "        \"If you need help picking travel destinations, ask 'travel_advisor' for help.\"\n",
    "        \"You MUST include human-readable response before transferring to another agent.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def call_hotel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"travel_advisor\", \"__end__\"]]:\n",
    "    return hotel_advisor.invoke(state)\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"travel_advisor\", call_travel_advisor)\n",
    "builder.add_node(\"hotel_advisor\", call_hotel_advisor)\n",
    "# we'll always start with a general travel advisor\n",
    "builder.add_edge(START, \"travel_advisor\")\n",
    "\n",
    "graph = builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132e2c0-d937-4325-a30e-e715c5304fe0",
   "metadata": {},
   "source": [
    "Let's test it out using the same input as our original multi-agent system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b47c57-ad05-4f10-83bf-c3ff6ff8eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"i wanna go somewhere warm in the caribbean. pick one destination and give me hotel recommendations\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    subgraphs=True,\n",
    "):\n",
    "    pretty_print_messages(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
